{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2722,
   "id": "d2154ba6-9357-420e-9cf5-8957088b767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "# Note: please don't add any new package, you should solve this problem using only the packages above.\n",
    "#-------------------------------------------------------------------------\n",
    "'''\n",
    "    Problem 1: Linear Regression\n",
    "    In this problem, you will implement the linear regression method based upon gradient descent.\n",
    "    Xw  = y\n",
    "    You could test the correctness of your code by typing `pytest -v test.py` in the terminal.\n",
    "    Note: please don't use any existing package for linear regression problem, implement your own version.\n",
    "'''\n",
    "\n",
    "#--------------------------\n",
    "def compute_Phi(x,p):\n",
    "    '''\n",
    "        Compute the feature matrix Phi of x. We will construct p polynoials, the p features of the data samples. \n",
    "        The features of each sample, is x^0, x^1, x^2 ... x^(p-1)\n",
    "        Input:\n",
    "            x : a vector of samples in one dimensional space, a numpy vector of shape (n,).\n",
    "                Here n is the number of samples.\n",
    "            p : the number of polynomials/features\n",
    "        Output:\n",
    "            Phi: the design/feature matrix of x, a numpy array of shape (n,p).\n",
    "    '''\n",
    "    #########################################\n",
    "    ## INSERT YOUR CODE HERE\n",
    "    #phi1(x) + phi2(x).....phid(x)\n",
    "    #h w (x) = w 0 + w 1 * phi1(x1) + w 2 * phi2(x2) + ... + w d * phid(xd)\n",
    "    columns = []\n",
    "    for i in range(p):\n",
    "        column = x**i\n",
    "        columns.append(column)\n",
    "    Phi = np.column_stack(columns)\n",
    "    \n",
    "\n",
    "\n",
    "    #########################################\n",
    "    return Phi \n",
    "\n",
    "#--------------------------\n",
    "def compute_yhat(Phi, w):\n",
    "    '''\n",
    "        Compute the linear logit value (predicted value) of all data instances. z = <w, x>\n",
    "        Here <w, x> represents the dot product of the two vectors.\n",
    "        Input:\n",
    "            Phi: the feature matrix of all data instance, a float numpy array of shape (n,p). \n",
    "            w: the weights parameter of the linear model, a float numpy array of shape (p,). \n",
    "        Output:\n",
    "            yhat: the logit value (predicted value) of all instances, a float numpy array of shape (n,)\n",
    "        Hint: you could solve this problem using 1 line of code. Though using more lines of code is also okay.\n",
    "    '''\n",
    "    #########################################\n",
    "    ## INSERT YOUR CODE HERE\n",
    "    # y hat or ŷ = h w (x) = w 0 + w 1 * phi1(x1) + w 2 * phi2(x2) + ... + w d * phid(xd)\n",
    "    yhat = Phi.dot(w)\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return yhat\n",
    "\n",
    "    #--------------------------\n",
    "def compute_L(yhat,y):\n",
    "    '''\n",
    "        Compute the loss function: mean squared error. In this function, divide the original mean squared error by 2 for making gradient computation simple. Remember our loss function in the slides.  \n",
    "        Input:\n",
    "            yhat: the predicted sample labels, a numpy vector of shape (n,).\n",
    "            y:  the sample labels, a numpy vector of shape (n,).\n",
    "        Output:\n",
    "            L: the loss value of linear regression, a float scalar.\n",
    "    '''\n",
    "    #########################################\n",
    "    ## INSERT YOUR CODE HERE\n",
    "    # L = J(theta or w) = (1/2n) * (((ŷ1 - y1) + (ŷ2 - y2) + ... (ŷn - yn))^2) \n",
    "    \n",
    "    L = np.mean((yhat-y)**2)/2\n",
    "\n",
    "    #########################################\n",
    "    return L \n",
    "\n",
    "\n",
    "\n",
    "def compute_dL_dw(y, yhat, Phi):\n",
    "    '''\n",
    "        Compute the gradients of the loss function L with respect to (w.r.t.) the weights w. \n",
    "        Input:\n",
    "            Phi: the feature matrix of all data instances, a float numpy array of shape (n,p). \n",
    "               Here p is the number of features/dimensions.\n",
    "            y: the sample labels, a numpy vector of shape (n,).\n",
    "            yhat: the predicted sample labels, a numpy vector of shape (n,).\n",
    "        Output:\n",
    "            dL_dw: the gradients of the loss function L with respect to the weights w, a numpy float array of shape (p,). \n",
    "\n",
    "    '''\n",
    "    #########################################\n",
    "    ## INSERT YOUR CODE HERE\n",
    "    # dl/dw = dJ(ŷ)/dw = (1/n) * ((((ŷ1(1)- y1(1)) + (ŷ2(1) - y2(1)) + ... (ŷd(1) - yd(1))) * xw1 +\n",
    "    #                              +   (ŷ1(2)- y1(2)) + (ŷ2(2) - y2(2)) + ... (ŷd(2) - yd(2))) * xw2 + ... \n",
    "    #                              + (((ŷ1(n) - y1(n)) + (ŷ2(n) - y2(n)) + ... (ŷd(n) - yd(n))) * xwn\n",
    "    n = len(y)\n",
    "    dL_dw = (1/n)*Phi.T.dot(yhat - y)\n",
    "\n",
    "    #########################################\n",
    "    return dL_dw\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "def update_w(w, dL_dw, alpha = 0.001):\n",
    "    '''\n",
    "       Given the instances in the training data, update the weights w using gradient descent.\n",
    "        Input:\n",
    "            w: the current value of the weight vector, a numpy float array of shape (p,).\n",
    "            dL_dw: the gradient of the loss function w.r.t. the weight vector, a numpy float array of shape (p,). \n",
    "            alpha: the step-size parameter of gradient descent, a float scalar.\n",
    "        Output:\n",
    "            w: the updated weight vector, a numpy float array of shape (p,).\n",
    "        Hint: you could solve this problem using 1 line of code\n",
    "    '''\n",
    "    \n",
    "    #########################################\n",
    "    ## INSERT YOUR CODE HERE\n",
    "    # w[j] := w[j] - alpha * dL_dw \n",
    "    \n",
    "    w = w - (alpha*dL_dw)\n",
    "\n",
    "    #########################################\n",
    "    return w\n",
    "\n",
    "\n",
    "#--------------------------\n",
    "def train(X, Y, alpha=0.001, n_epoch=100):  \n",
    "    '''\n",
    "       Given a training dataset, train the linear regression model by iteratively updating the weights w using the gradient descent\n",
    "        We repeat n_epoch passes over all the training instances.\n",
    "        Input:\n",
    "            X: the feature matrix of training instances, a float numpy array of shape (n, p). Here n is the number of data instance in the training set, p is the number of features/dimensions.\n",
    "            Y: the labels of training instance, a numpy integer array of shape (n,). \n",
    "            alpha: the step-size parameter of gradient descent, a float scalar.\n",
    "            n_epoch: the number of passes to go through the training set, an integer scalar.\n",
    "        Output:\n",
    "            w: the weight vector trained on the training set, a numpy float array of shape (p,). \n",
    "    '''\n",
    "\n",
    "    # initialize weights as 0\n",
    "    w = np.array(np.zeros(X.shape[1])).T\n",
    "\n",
    "    for _ in range(n_epoch):\n",
    "\n",
    "    #########################################\n",
    "    ## INSERT YOUR CODE HERE\n",
    "\n",
    "    # Back propagation: compute local gradients \n",
    "\n",
    "        yhat = compute_yhat(X, w)\n",
    "        dL_dw = compute_dL_dw(Y, yhat, X)\n",
    "        \n",
    "        \n",
    "    # update the parameters w\n",
    "        w = update_w(w, dL_dw, alpha)\n",
    "\n",
    "    #########################################\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "ddedae60-791c-48a5-a2f3-db14f61f0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1  1]\n",
      " [ 1  2  4]\n",
      " [ 1  3  9]\n",
      " [ 1  4 16]]\n",
      "Trying it the other way\n",
      "0\n",
      "column: [1 1 1 1]\n",
      "columns: [array([1, 1, 1, 1])]\n",
      "1\n",
      "column: [1 2 3 4]\n",
      "columns: [array([1, 1, 1, 1]), array([1, 2, 3, 4])]\n",
      "2\n",
      "column: [ 1  4  9 16]\n",
      "columns: [array([1, 1, 1, 1]), array([1, 2, 3, 4]), array([ 1,  4,  9, 16])]\n",
      "[[ 1  1  1]\n",
      " [ 1  2  4]\n",
      " [ 1  3  9]\n",
      " [ 1  4 16]]\n"
     ]
    }
   ],
   "source": [
    "###Testing on the go\n",
    "import numpy as np\n",
    "x=np.array([1,2,3,4])\n",
    "p=3\n",
    "Phi = np.column_stack([x**i for i in range(p)])\n",
    "print(Phi)\n",
    "\n",
    "print('Trying it the other way')\n",
    "columns = []\n",
    "for i in range(p):\n",
    "    column = x**i\n",
    "    columns.append(column)\n",
    "    print(i)\n",
    "    print(f'column: {column}')\n",
    "    print(f'columns: {columns}')\n",
    "Phi2 = np.column_stack(columns)\n",
    "print(Phi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "1eca0158-a470-47c0-b966-5bc11e2faf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32  59 100 155]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([19,6,7])\n",
    "yhat = Phi2.dot(w)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "f25db63f-84fe-4768-a4be-25c34a99a17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183.875\n"
     ]
    }
   ],
   "source": [
    "y = np.array([190, 46, 87, 142])\n",
    "L = np.mean((yhat-y)**2)/2\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "d11f1e55-6562-4e9e-a201-ef07c6542ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-29.75 -10.25  54.75]\n"
     ]
    }
   ],
   "source": [
    "n = len(y)\n",
    "dL_dw = (1/n)*Phi.T.dot(yhat - y)\n",
    "print(dL_dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2653,
   "id": "2ceeb10f-a085-4e7f-b909-779fd93e0270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115.72984738  -8.87047413   2.37515961]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "w = w - (alpha*dL_dw)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2694,
   "id": "cacc5c17-ac13-44f6-bdce-99b2f8ed2234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.63692766e+22 -3.27329037e+23 -6.98941251e+23 -1.21120592e+24]\n",
      "[-5.83461371e+23 -1.92316869e+24 -6.76886285e+24]\n",
      "[5.22841681e+22 1.72335788e+23 6.06560058e+23]\n",
      "2.58996248203771e+47\n"
     ]
    }
   ],
   "source": [
    "yhat = Phi2.dot(w)\n",
    "print(yhat)\n",
    "dL_dw = (1/n)*Phi.T.dot(yhat - y)\n",
    "print(dL_dw)\n",
    "w = w - (alpha*dL_dw)\n",
    "print(w)\n",
    "L = np.mean((yhat-y)**2)/2\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2721,
   "id": "3d16e14e-ab0a-4e18-83c8-48a957feae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.63692766e+22 -3.27329037e+23 -6.98941251e+23 -1.21120592e+24]\n",
      "[190  46  87 142]\n"
     ]
    }
   ],
   "source": [
    "print(yhat)\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
